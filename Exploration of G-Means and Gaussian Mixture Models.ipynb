{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: App behaviour is normally distributed\n",
    "\n",
    "    1) The activity vectors are sampled from a Gaussian distribution\n",
    "    2) The clusters with normal distributions represent samples generated from a hidden Markov process\n",
    "    3) To test this, we must first observe whether the data can be split into clusters with Gaussian distributions at a significance level of 0.001\n",
    "    4) This test will be done via the G-Means algorithm [1]\n",
    "    \n",
    "[1] Hamerly, G., & Elkan, C. (n.d.). Learning the k in k -means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "from utils import *\n",
    "import gmeans\n",
    "import gmpp\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_percentage = 0.8\n",
    "explained_variance = 0.8\n",
    "df = pd.read_csv(\"data/rescuetime_data-ac-min.csv\")\n",
    "data_pd = Clean_DF(df)\n",
    "data_pd.clean_data(time_percentage=time_percentage)\n",
    "data_pd.clean_df = data_pd.clean_df.reset_index()\n",
    "data_pd.get_pca(explained_variance=explained_variance)\n",
    "data_pd.get_day_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-Means\n",
    "\n",
    "#### Algorithm: \n",
    "\n",
    "    1) Start from k=1      \n",
    "    2) Test whether data in each cluster is a Gaussian via the Anderson-Darling test at alpha = 0.0001       \n",
    "    3) if data is Gaussian, keep center      \n",
    "    4) else, split cluster into two sub clusters and repeat from 2      \n",
    "\n",
    "\n",
    "#### Gaussian test:      \n",
    "    \n",
    "    1) Run k-means on sub-data X with k=2      \n",
    "    2) Compute v = c1 - c2 where c1 & c2 are the two new cluster centres found by k-means on X \n",
    "    3) Project X onto v Xv = dot(X,v)/dot(v,v)      \n",
    "    4) Scale Xv to mean 0 and unit variance      \n",
    "    5) apply Anderson-Darling test to this vector      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import f\n",
    "# print(np.sqrt(f.ppf(0.99, 2, 10000, loc=0, scale=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4cf26ef53671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "print(cm.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(loc=(5,5), scale=(2,2), size=(1000,2))\n",
    "B = np.random.normal(loc=(1,22), scale=(2,2), size=(1000,2))\n",
    "C = np.random.normal(loc=(30,10), scale=(2,2), size=(2000,2))\n",
    "D = np.random.normal(loc=(18,8), scale=(3,3), size=(2000,2))\n",
    "E = np.random.normal(loc=(50,50), scale=(3,3), size=(1000,2))\n",
    "\n",
    "X = np.concatenate((A,B,C,D,E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asturkmani/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:889: RuntimeWarning:\n",
      "\n",
      "Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[ 49.98156021  50.20991596]\n",
      " [  1.07308296  22.0758027 ]\n",
      " [ 19.02559005  10.15671739]\n",
      " [  4.99334129   5.01275083]\n",
      " [ 17.00990126   5.87141711]\n",
      " [ 29.94056788   9.98738941]]\n"
     ]
    }
   ],
   "source": [
    "cm = gmpp.GMeans(verbose=0, trim_points=True, recalculate_points=True, significance_level=0.99, critical_value = 1.865)\n",
    "cm.fit(X)\n",
    "print(len(cm.cluster_centers_))\n",
    "print(cm.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asturkmani/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:889: RuntimeWarning:\n",
      "\n",
      "Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm = gmeans.GMeans(verbose=0, trim_points=False)\n",
    "gm.fit(X)\n",
    "print(len(gm.cluster_centers_))\n",
    "gaussian_clusters_gm = gm.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gm.cluster_centers_)\n",
    "kmeans = KMeans(n_clusters=len(gaussian_clusters), init=gaussian_clusters)\n",
    "kmeans.fit(D)\n",
    "\n",
    "c = gm.labels_\n",
    "trace = go.Scatter(x=X[:,0], y=X[:,1], mode='markers', marker=dict(\n",
    "        size='10',\n",
    "        color = c, #set color equal to a variable\n",
    "        colorscale='Viridis',\n",
    "        showscale=True\n",
    "    ))\n",
    "data= [trace]\n",
    "py.iplot(data, filename='K-Means inerta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=len(gaussian_clusters), init=gaussian_clusters)\n",
    "kmeans.fit(D)\n",
    "\n",
    "c = cm.labels_\n",
    "trace = go.Scatter(x=X[:,0], y=X[:,1], mode='markers', marker=dict(\n",
    "        size='10',\n",
    "        color = c, #set color equal to a variable\n",
    "        colorscale='Viridis',\n",
    "        showscale=True\n",
    "    ))\n",
    "data= [trace]\n",
    "py.iplot(data, filename='K-Means inerta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = Cantankerousmeans.GMeans(verbose=0, trim_points=True, recalculate_points=True, significance_level=0.99, critical_value = 1.865)\n",
    "cm.fit(data_pd.pca_data)\n",
    "print(len(cm.cluster_centers_))\n",
    "print(cm.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cm.labels_\n",
    "x = data_pd.pca_data[:,0]\n",
    "y = data_pd.pca_data[:,1]\n",
    "z = data_pd.pca_data[:,2]\n",
    "t = data_pd.clean_df['Activity']\n",
    "t = data_pd.clean_df['Activity'].tolist()\n",
    "t = ['-'.join(x) for x in t]\n",
    "for i in range(0,len(t)):\n",
    "    t[i] = str(cm.labels_[i]) + '---' + t[i]\n",
    "    \n",
    "trace1 = go.Scatter3d(x=x,y=y,z=z,text=t,mode='markers',marker=dict(size=12,color=c, colorscale='Viridis',opacity=0.8))\n",
    "data = [trace1]\n",
    "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='PCA-3 Visualization with G-Means')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_pca = TSNE(n_components=3, verbose=0, perplexity=30, n_iter=5000)\n",
    "tsne_results_pca = tsne_pca.fit_transform(data_pd.pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = gm.labels_\n",
    "x = tsne_results_pca[:,0]\n",
    "y = tsne_results_pca[:,1]\n",
    "z = tsne_results_pca[:,2]\n",
    "# t = data_pd.clean_df['Activity']\n",
    "# t = data_pd.clean_df['Activity'].tolist()\n",
    "# t = ['-'.join(x) for x in t]\n",
    "\n",
    "trace1 = go.Scatter3d(x=x,y=y,z=z,text=t,mode='markers',marker=dict(size=12,color=c, colorscale='RdYlGn',opacity=0.8))\n",
    "data = [trace1]\n",
    "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='t-SNE PCA 90% variance Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 20)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "X = data_pd.pca_data\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        # Fit a Gaussian mixture with EM\n",
    "        gmm = mixture.GaussianMixture(n_components=n_components,\n",
    "                                      covariance_type=cv_type)\n",
    "        gmm.fit(X)\n",
    "        bic.append(gmm.bic(X))\n",
    "        if (bic[-1] < lowest_bic):\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "\n",
    "bic = np.array(bic)\n",
    "color_iter = itertools.cycle(['navy', 'turquoise', 'cornflowerblue',\n",
    "                              'darkorange'])\n",
    "clf = best_gmm\n",
    "bars = []\n",
    "lowest_bic = max(bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bic)\n",
    "# Plot the BIC scores\n",
    "spl = plt.subplot(2, 1, 1)\n",
    "for i, (cv_type, color) in enumerate(zip(cv_types, color_iter)):\n",
    "    xpos = np.array(n_components_range) + .2 * (i - 2)\n",
    "    bars.append(plt.bar(xpos, bic[i * len(n_components_range):\n",
    "                                  (i + 1) * len(n_components_range)],\n",
    "                        width=.2, color=color))\n",
    "plt.xticks(n_components_range)\n",
    "plt.ylim([bic.min() * 1.01 - .01 * bic.max(), bic.max()])\n",
    "plt.title('BIC score per model')\n",
    "xpos = np.mod(bic.argmin(), len(n_components_range)) + .65 +\\\n",
    "    .2 * np.floor(bic.argmin() / len(n_components_range))\n",
    "plt.text(xpos, bic.min() * 0.97 + .03 * bic.max(), '*', fontsize=14)\n",
    "spl.set_xlabel('Number of components')\n",
    "spl.legend([b[0] for b in bars], cv_types)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
