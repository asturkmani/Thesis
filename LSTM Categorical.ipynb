{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import h5py\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, GRU\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import regularizers\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "# plotly.tools.set_credentials_file(username='AbdelWahabTurkmani', api_key='zTY632QGUJbqSVFms8bQ')\n",
    "# plotly.tools.set_credentials_file(username='asturkmani', api_key='bR0Ez8evmzcHY6m4XG7B')\n",
    "plotly.tools.set_credentials_file(username='asturkmanics', api_key='GaUFc6cWCQVW0eCz6K75')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_percentage = 0.7\n",
    "explained_variance = 0.9\n",
    "df = pd.read_csv(\"data/rescuetime_data-ac-min.csv\")\n",
    "data_pd = Clean_DF(df)\n",
    "data_pd.clean_data(time_percentage=time_percentage)\n",
    "data_pd.clean_df = data_pd.clean_df.reset_index()\n",
    "data_pd.get_pca(explained_variance=explained_variance)\n",
    "data_pd.get_day_time()\n",
    "\n",
    "# Saving the objects:\n",
    "with open('data_pd_70.pickle', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(data_pd, f)\n",
    "\n",
    "# # Getting back the objects:\n",
    "# with open('data/data_pd_80.pickle', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "#     data_pd = pickle.load(f)\n",
    "# time_percentage = 0.8\n",
    "# explained_variance = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (16704, 9) \n",
      "\n",
      "Number of apps that consume 70.0 % of all users time:  24 \n",
      "\n",
      "Cleaned dataset columns: \n",
      " ['Date' 'Time Spent (seconds)' 'Activity' 'Category' 'Productivity'\n",
      " 'Activity Vector' 'Productivity Score' 'Day' 'Time'] \n",
      "\n",
      "Number of components that explain 90.0 % of the data:  12 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", data_pd.clean_df.shape,'\\n')\n",
    "print(\"Number of apps that consume\", time_percentage*100, \"% of all users time: \",len(data_pd.popular_apps), '\\n')\n",
    "print(\"Cleaned dataset columns:\",'\\n', data_pd.clean_df.columns.values, '\\n')\n",
    "print(\"Number of components that explain\", explained_variance*100,\"% of the data: \",data_pd.pca_data.shape[1], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~asturkmanics/28.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter(x=[i for i in range(data_pd.app_idx)], y=data_pd.app_cdf[:data_pd.app_idx], mode='markers')\n",
    "data= [trace]\n",
    "py.iplot(data, filename='App distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.flags\n",
    "FLAGS.look_back = 12 #lookback over a 1 hour period\n",
    "FLAGS.batch_size = 10\n",
    "FLAGS.inputlength = data_pd.activity_vector.shape[1]\n",
    "np.random.seed(7)\n",
    "dataset = data_pd.activity_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = np.round(data_pd.activity_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def get_time(day):\n",
    "    day = day + dt.timedelta(minutes=5*84)\n",
    "    all_times = [day + dt.timedelta(minutes=5*x) for x in range(204)]\n",
    "    return all_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = data_pd.clean_df[['Day']].values\n",
    "days = np.unique(days)\n",
    "total_time = [get_time(pd.to_datetime(x)) for x in days]\n",
    "len(total_time[0])\n",
    "# total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.flags\n",
    "FLAGS.look_back = 12 #lookback over a 1 hour period\n",
    "FLAGS.batch_size = 10\n",
    "FLAGS.inputlength = data_pd.activity_vector.shape[1]\n",
    "np.random.seed(7)\n",
    "dataset = data_pd.activity_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into overlapping sentences with step size 3.\n",
    "def split2sequences(data, maxlen):\n",
    "    print('Splitting text into sequences...')\n",
    "    sequencelen = maxlen\n",
    "    step = 1\n",
    "    sequences = []\n",
    "    response = []\n",
    "    for i in range(0, len(data) - sequencelen - 1, step):\n",
    "        sequences.append(data[i: i + sequencelen])\n",
    "        response.append(data[i + sequencelen + 1])\n",
    "    return np.array(sequences), np.array(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting text into sequences...\n"
     ]
    }
   ],
   "source": [
    "xN, yN = split2sequences(dataset, FLAGS.look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16691, 12, 24)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(xN) * 0.8)\n",
    "test_size = len(xN) - train_size\n",
    "X_train, X_test = xN[0:train_size], xN[train_size:len(dataset)]\n",
    "Y_train, Y_test = yN[0:train_size], yN[train_size:len(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (13352, 12, 24)\n",
      "Y_train shape:  (13352, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape:  (3339, 12, 24)\n",
      "Y_test shape:  (3339, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"Y_test shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_HIDDEN = 32\n",
    "N_DENSE = 64\n",
    "LEARNING_RATE = 0.005\n",
    "DECAY = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_3 (LSTM)                    (None, 32)            7296        lstm_input_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 32)            0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 32)            1056        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 32)            0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 24)            792         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 9,144\n",
      "Trainable params: 9,144\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Building training model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(N_HIDDEN, input_shape=(FLAGS.look_back, FLAGS.inputlength)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(N_HIDDEN, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(FLAGS.inputlength, activation='softmax'))  # Add another dense layer with the desired output size.\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = RMSprop(lr=LEARNING_RATE, clipnorm=5))\n",
    "\n",
    "print(model.summary()) # Convenient function to see details about the network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13352 samples, validate on 3339 samples\n",
      "Epoch 1/10\n",
      " 1910/13352 [===>..........................] - ETA: 74s - loss: 2.1119"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train, y=Y_train, validation_data=(X_test, Y_test), nb_epoch=EPOCHS, batch_size=FLAGS.batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
