{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script> code_show_err=false;  function code_toggle_err() {if (code_show_err){$('div.output_stderr').hide();} else {$('div.output_stderr').show();}code_show_err = !code_show_err} $( document ).ready(code_toggle_err);</script>To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "from utils import *\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "__date__ = '2017-08-04'\n",
    "%matplotlib inline\n",
    "HTML('''<script> code_show_err=false;  function code_toggle_err() {if (code_show_err){$('div.output_stderr').hide();} else {$('div.output_stderr').show();}code_show_err = !code_show_err} $( document ).ready(code_toggle_err);</script>To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 6, 15)             0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 6, 64)             20480     \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 6, 15)             975       \n",
      "_________________________________________________________________\n",
      "VAE (TimeDistributed)        (None, 6, 15)             627       \n",
      "=================================================================\n",
      "Total params: 22,082\n",
      "Trainable params: 22,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 606.00 304.00\" width=\"606pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 602,-300 602,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139953609686880 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139953609686880</title>\n",
       "<polygon fill=\"none\" points=\"125.5,-249.5 125.5,-295.5 472.5,-295.5 472.5,-249.5 125.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-268.8\">input_22: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"294.5,-249.5 294.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"294.5,-272.5 362.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"362.5,-249.5 362.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-280.3\">(None, 6, 15)</text>\n",
       "<polyline fill=\"none\" points=\"362.5,-272.5 472.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-257.3\">(None, 6, 15)</text>\n",
       "</g>\n",
       "<!-- 139953609586112 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139953609586112</title>\n",
       "<polygon fill=\"none\" points=\"147.5,-166.5 147.5,-212.5 450.5,-212.5 450.5,-166.5 147.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-185.8\">lstm_13: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"272.5,-166.5 272.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"272.5,-189.5 340.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"340.5,-166.5 340.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395.5\" y=\"-197.3\">(None, 6, 15)</text>\n",
       "<polyline fill=\"none\" points=\"340.5,-189.5 450.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395.5\" y=\"-174.3\">(None, 6, 64)</text>\n",
       "</g>\n",
       "<!-- 139953609686880&#45;&gt;139953609586112 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139953609686880-&gt;139953609586112</title>\n",
       "<path d=\"M299,-249.366C299,-241.152 299,-231.658 299,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"302.5,-222.607 299,-212.607 295.5,-222.607 302.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139953544125912 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139953544125912</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 598,-129.5 598,-83.5 0,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-102.8\">time_distributed_30(dense_66): TimeDistributed(Dense)</text>\n",
       "<polyline fill=\"none\" points=\"420,-83.5 420,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"420,-106.5 488,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"488,-83.5 488,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"543\" y=\"-114.3\">(None, 6, 64)</text>\n",
       "<polyline fill=\"none\" points=\"488,-106.5 598,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"543\" y=\"-91.3\">(None, 6, 15)</text>\n",
       "</g>\n",
       "<!-- 139953609586112&#45;&gt;139953544125912 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139953609586112-&gt;139953544125912</title>\n",
       "<path d=\"M299,-166.366C299,-158.152 299,-148.658 299,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"302.5,-139.607 299,-129.607 295.5,-139.607 302.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139953609307024 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139953609307024</title>\n",
       "<polygon fill=\"none\" points=\"56,-0.5 56,-46.5 542,-46.5 542,-0.5 56,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-19.8\">VAE(model_14): TimeDistributed(Model)</text>\n",
       "<polyline fill=\"none\" points=\"364,-0.5 364,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"364,-23.5 432,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"432,-0.5 432,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487\" y=\"-31.3\">(None, 6, 15)</text>\n",
       "<polyline fill=\"none\" points=\"432,-23.5 542,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487\" y=\"-8.3\">(None, 6, 15)</text>\n",
       "</g>\n",
       "<!-- 139953544125912&#45;&gt;139953609307024 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139953544125912-&gt;139953609307024</title>\n",
       "<path d=\"M299,-83.3664C299,-75.1516 299,-65.6579 299,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"302.5,-56.6068 299,-46.6068 295.5,-56.6069 302.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define VAE\n",
    "original_dim = 15\n",
    "hidden_dim = 64\n",
    "intermediate_dim = 16\n",
    "latent_dim = 2\n",
    "window_size = 6\n",
    "batch_size = 20\n",
    "epsilon_std = 1.\n",
    "\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "\n",
    "# Custom loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = original_dim * metrics.mse(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded_mean)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x\n",
    "\n",
    "y = CustomVariationalLayer()([x, x_decoded_mean])\n",
    "vae = Model(x, y)\n",
    "\n",
    "# Define LSTM\n",
    "X = Input(shape=(window_size, original_dim))\n",
    "h_lstm = LSTM(64, activation='relu', return_sequences=True)(X)\n",
    "h_lstm_dense = TimeDistributed(Dense(original_dim, activation='elu'))(h_lstm)\n",
    "\n",
    "outputs = TimeDistributed(vae, name='VAE')(h_lstm_dense)\n",
    "\n",
    "varnn = Model(X, outputs)\n",
    "varnn.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "print(varnn.summary())\n",
    "SVG(model_to_dot(varnn, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split2sequences(data, length_x=1, length_y=1, split=0.8):\n",
    "    print('Splitting text into sequences...', \"\\n\",)\n",
    "    step = 1\n",
    "    xN = []\n",
    "    yN = []\n",
    "    \n",
    "    for i in range(0, len(data) - length_x, step):\n",
    "        xN.append(data[i: i + length_x])\n",
    "        yN.append(data[i+1+length_x-length_y:i + length_x + 1])\n",
    "        \n",
    "    train_size = int(len(xN) * split)\n",
    "    test_size = len(xN) - train_size\n",
    "    \n",
    "    xN = np.array(xN)\n",
    "    yN = np.array(yN)\n",
    "    n = len(data)\n",
    "    X_train, X_test = xN[0:train_size],  xN[train_size:n]\n",
    "    Y_train,Y_test = yN[0:train_size], yN[train_size:n]\n",
    "\n",
    "    return xN, yN, X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_clean_data(window_size,batch_size, val_size=0.2,multiplier=300, process = False, time_percentage=0.9, explained_variance=0.9):\n",
    "    filename = 'data.pickle'\n",
    "    delete_other_idle = False\n",
    "    if (process):\n",
    "        df = pd.read_csv('data/rescuetime_data_category_2017-07-21.csv')\n",
    "        data = Clean_DF(df)\n",
    "        data.clean_data(time_percentage=time_percentage)\n",
    "        data.clean_df = data.clean_df.reset_index()\n",
    "        data.get_pca(explained_variance=explained_variance)\n",
    "        data.get_day_time()\n",
    "\n",
    "        with open(filename, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "            pickle.dump(data, f)\n",
    "    else:\n",
    "        with open(filename, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "            data = pickle.load(f)\n",
    "\n",
    "    dataset = data.activity_vector\n",
    "    popular_apps = data.popular_apps\n",
    "\n",
    "\n",
    "    if (delete_other_idle):\n",
    "    # Remove IDLE and OTHER time\n",
    "        dataset = np.delete(dataset, [dataset.shape[1]-1,dataset.shape[1]-2], axis=1)\n",
    "        del popular_apps[-1]\n",
    "        del popular_apps[-1]\n",
    "\n",
    "\n",
    "\n",
    "#     weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday','Saturday','Sunday']\n",
    "\n",
    "\n",
    "#     days = set(data.clean_df['Day'])\n",
    "#     df = data.clean_df[['Date', 'Activity Vector']]\n",
    "#     df['timestamp'] = pd.to_datetime(df['Date'])\n",
    "#     # print(df.dtypes)\n",
    "#     df = df.set_index('timestamp').resample('300S').asfreq()\n",
    "#     x = {'val': np.zeros(15)}\n",
    "#     df['Activity Vector'] = df['Activity Vector'].fillna(x)\n",
    "#     del df['Date']\n",
    "#     df['Activity Vector'] = df['Activity Vector'].map(lambda x: np.zeros(len(popular_apps)) if np.isnan(np.sum(x)) else x)\n",
    "#     df = df.reset_index()\n",
    "#     dataset = df['Activity Vector']\n",
    "#     dataset = np.asarray(dataset.tolist())\n",
    "\n",
    "#     day_categorical = np.asarray(df.timestamp.dt.weekday)\n",
    "#     time_categorical = np.asarray(df.timestamp.dt.time.map(lambda x: int(str(x)[0:2])))\n",
    "\n",
    "    (Xc, yc, X_train_c, X_test_c, y_train_c, y_test_c)= split2sequences(dataset*multiplier, length_x=window_size, length_y=window_size, split=0.8)\n",
    "#     (Xd, yd, X_train_d, X_test_d, y_train_d, y_test_d)= split2sequences(day_categorical, length_x=window_size, length_y=window_size, split=0.8)\n",
    "#     (Xt, yt, X_train_t, X_test_t, y_train_t, y_test_t)= split2sequences(day_categorical, length_x=window_size, length_y=window_size, split=0.8)\n",
    "\n",
    "#     indices = ~np.all(yc == 0, axis=1)\n",
    "#     print(Xc.shape)\n",
    "#     print(yc.shape)\n",
    "#     print(len(indices))\n",
    "#     Xc = Xc[indices, :, :]\n",
    "#     yc = yc[indices, :]\n",
    "    \n",
    "#     Xd = Xd[indices,:]\n",
    "#     yd = yd[indices]\n",
    "    \n",
    "#     Xt = Xt[indices,:]\n",
    "#     yt = yt[indices]\n",
    "    \n",
    "    \n",
    "    test_size = int(val_size * Xc.shape[0])           # In real life you'd want to use 0.2 - 0.5\n",
    "    x_train_c, x_test_c, y_train_c, y_test_c = Xc[:-test_size], Xc[-test_size:], yc[:-test_size], yc[-test_size:]\n",
    "#     Xt = Xt.reshape(Xt.shape[0],Xt.shape[1])\n",
    "#     Xd = Xd.reshape(Xt.shape[0],Xt.shape[1])\n",
    "#     x_train_t, x_test_t = Xt[:-test_size], Xt[-test_size:]\n",
    "#     x_train_d, x_test_d = Xd[:-test_size], Xd[-test_size:]\n",
    "    \n",
    "    l_total = int(len(Xc)/batch_size)*batch_size\n",
    "    l_train = int(len(x_train_c)/batch_size)*batch_size\n",
    "    l_test = int(len(x_test_c)/batch_size)*batch_size\n",
    "    \n",
    "    Xc = Xc[:l_total]\n",
    "    yc = yc[:l_total]\n",
    "    x_train_c = x_train_c[:l_train]\n",
    "    x_test_c = x_test_c[:l_test]\n",
    "    y_train_c = y_train_c[:l_train]\n",
    "    y_test_c = y_test_c[:l_test]\n",
    "    \n",
    "#     x_train_t = x_train_t[:l_train]\n",
    "#     x_test_t = x_test_t[:l_test]\n",
    "\n",
    "#     x_train_d = x_train_d[:l_train]\n",
    "#     x_test_d = x_test_d[:l_test]\n",
    "    \n",
    "    y_train_labels = [dict(zip(popular_apps, np.round(300*x))) for x in y_train_c]\n",
    "    y_test_labels = [dict(zip(popular_apps, np.round(300*x))) for x in y_test_c]\n",
    "    y_labels = [dict(zip(popular_apps, np.round(300*x))) for x in yc]\n",
    "\n",
    "    \n",
    "#     cmap = {\n",
    "#         'Instant Message' : (255,255,0),\n",
    "#         'Video' : (255,0,0),\n",
    "#         'General Software Development' : (255,0,200),\n",
    "#         'General Social Networking' : (255,127,0),\n",
    "#         'Writing' : (200,0,255),\n",
    "#         'Browsers' : (0,255,200),\n",
    "#         'General Reference & Learning' : (127,0,255),\n",
    "#         'Email' : (127,255,0),\n",
    "#         'Search' : (0,255,127),\n",
    "#         'Uncategorized' : (128,128,128),\n",
    "#         'General News & Opinion' : (0,200,255),\n",
    "#         'Engineering & Technology' : (0,127,255),\n",
    "#         'General Business' : (0,0,255),\n",
    "#         'Voice Chat' : (200,255,0),\n",
    "#         'other' : (200,200,200)\n",
    "#     }\n",
    "#     cmap = np.array([[255,255,0], [255,0,0], [255,0,200], \n",
    "#                      [255,127,0], [200,0,255], [0,255,200], \n",
    "#                      [127,0,255], [127,255,0], [0,255,127],\n",
    "#                      [128,128,128],[0,200,255], [0,127,255], \n",
    "#                      [0,0,255], [200,255,0],  [200,200,200]])\n",
    "#     yc_colors = convert_to_rgb(np.einsum('ij,jk->ik', data_['yc'], cmap))\n",
    "#     y_train_c_colors = convert_to_rgb(np.einsum('ij,jk->ik', data_['y_train_c'], cmap))\n",
    "#     y_test_c_colors = convert_to_rgb(np.einsum('ij,jk->ik', data_['y_test_c'], cmap))\n",
    "#     data_colors = convert_to_rgb(cmap)\n",
    "    \n",
    "    data_ = {\n",
    "        'Xc' : Xc,\n",
    "        'yc' : yc,\n",
    "        'x_train_c' : x_train_c,\n",
    "        'x_test_c' : x_test_c,\n",
    "        'y_train_c' : y_train_c,\n",
    "        'y_test_c' : y_test_c,\n",
    "#         'x_train_t' : x_train_t,\n",
    "#         'x_test_t' : x_test_t,\n",
    "#         'x_train_d' : x_train_d,\n",
    "#         'x_test_d' : x_test_d,\n",
    "        'popular_apps' : popular_apps,\n",
    "#         'days' : len(set(day_categorical)),\n",
    "#         'time' : len(set(time_categorical)),\n",
    "#         'day_categorical' : day_categorical,\n",
    "#         'time_categorical' : time_categorical,\n",
    "        'dataset' : dataset,\n",
    "#         'y_train_labels' : y_train_labels,\n",
    "#         'y_test_labels' : y_test_labels,\n",
    "#         'y_labels' : y_labels,\n",
    "#         'yc_colors' : yc_colors,\n",
    "#         'y_train_c_colors' : y_train_c_colors,\n",
    "#         'y_test_c_colors' : y_test_c_colors,\n",
    "#         'data_colors' : data_colors\n",
    "    }\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting text into sequences... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_ = make_clean_data(window_size=6,batch_size=20, val_size=0.2,multiplier=300, process = False, time_percentage=0.9, explained_variance=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14620, 6, 15)\n",
      "(14620, 6, 15)\n"
     ]
    }
   ],
   "source": [
    "print(data_['x_train_c'].shape)\n",
    "print(data_['y_train_c'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
