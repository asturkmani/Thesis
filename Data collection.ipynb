{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "# from sklearn import cross_validation\n",
    "from keras import regularizers\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_percentage = 0.9\n",
    "explained_variance = 0.9\n",
    "df = pd.read_csv(\"rescuetime_data-ac-min.csv\")\n",
    "data_pd = Clean_DF(df)\n",
    "data_pd.clean_data(time_percentage=time_percentage)\n",
    "data_pd.clean_df = data_pd.clean_df.reset_index()\n",
    "\n",
    "# print(data_pd.clean_df)\n",
    "# print(data_pd.popular_apps)\n",
    "# data_pd.get_pca(explained_variance=explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", data_pd.clean_df.shape,'\\n')\n",
    "print(\"Number of apps that consume\", time_percentage*100, \"% of all users time: \",len(data_pd.popular_apps), '\\n')\n",
    "print(\"Cleaned dataset columns:\",'\\n', data_pd.clean_df.columns.values, '\\n')\n",
    "print(\"Number of components that explain\", explained_variance*100,\"% of the data: \",data_pd.pca_data.shape[1], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t-SNE embedding, perplexity = 75\n",
    "ptsne100 = TSNE(n_components=3, verbose=0, perplexity=30, n_iter=5000)\n",
    "ptsne_results100 = ptsne100.fit_transform(pca_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_np = np.array(data_pd.clean_df['Activity Vector'].tolist())\n",
    "# PCA decomposition\n",
    "sk_kPCA = KernelPCA(kernel=\"rbf\", n_components=30)\n",
    "kpca_data = sk_kPCA.fit_transform(data_np)\n",
    "# print(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = data_pd.clean_df['Productivity Score'][-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t-SNE embedding, perplexity = 25\n",
    "ktsne100 = TSNE(n_components=3, verbose=0, perplexity=100, n_iter=20000)\n",
    "ktsne_results100 = ktsne100.fit_transform(kpca_data[-2000:])\n",
    "\n",
    "# t-SNE embedding, perplexity = 25\n",
    "ktsne75 = TSNE(n_components=3, verbose=0, perplexity=75, n_iter=20000)\n",
    "ktsne_results75 = ktsne75.fit_transform(kpca_data[-2000:])\n",
    "\n",
    "# t-SNE embedding, perplexity = 25\n",
    "ktsne30 = TSNE(n_components=3, verbose=0, perplexity=50, n_iter=20000)\n",
    "ktsne_results30 = ktsne30.fit_transform(kpca_data[-2000:])\n",
    "\n",
    "# t-SNE embedding, perplexity = 25\n",
    "ktsne5 = TSNE(n_components=3, verbose=0, perplexity=5, n_iter=20000)\n",
    "ktsne_results5 = ktsne5.fit_transform(kpca_data[-2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = ktsne_results100[:,0]\n",
    "# y = ktsne_results100[:,1]\n",
    "# z = ktsne_results100[:,2]\n",
    "\n",
    "# trace1 = go.Scatter3d(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     z=z,\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=12,\n",
    "#         color=c,                # set color to an array/list of desired values\n",
    "#         colorscale='RdYlGn',   # choose a colorscale\n",
    "#         opacity=0.8\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# data = [trace1]\n",
    "# layout = go.Layout(\n",
    "#     margin=dict(\n",
    "#         l=0,\n",
    "#         r=0,\n",
    "#         b=0,\n",
    "#         t=0\n",
    "#     )\n",
    "# )\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "# py.iplot(fig, filename='t-SNE Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "input_size = len(data_pd.clean_df['Activity Vector'][0])\n",
    "# print(input_size)\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(input_size,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(input_size, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.matrix(data_pd.clean_df['Activity Vector'].tolist())\n",
    "# print(data.shape)\n",
    "\n",
    "# train, validate = cross_validation.train_test_split(data, train_size=0.8, test_size=0.2)\n",
    "\n",
    "# # train = train.transpose()\n",
    "# # validate = validate.transpose()\n",
    "# print(train.shape)\n",
    "# print(validate.shape)\n",
    "\n",
    "# # train.reshape((input_size, len(train)))\n",
    "# # validate.reshape((input_size, len(validate)))\n",
    "\n",
    "\n",
    "# autoencoder.fit(x=train, y=train,\n",
    "#                 verbose=0,\n",
    "#                 nb_epoch=100,\n",
    "#                 batch_size=256,\n",
    "#                 shuffle=True,\n",
    "#                 validation_data=(validate, validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Encode data\n",
    "# encoded_vecs = encoder.predict(data)\n",
    "# t-SNE embedding\n",
    "# tsne = TSNE(n_components=2, verbose=1, perplexity=5, n_iter=5000)\n",
    "# tsne_results = tsne.fit_transform(encoded_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoded with AE into 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder, Perplexity = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational AutoEncoder 2-D Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "original_dim = input_size\n",
    "latent_dim = 3\n",
    "intermediate_dim = 15\n",
    "epochs = 25\n",
    "epsilon_std = 1.0\n",
    "\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return xent_loss + kl_loss\n",
    "\n",
    "\n",
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train, validate\n",
    "print(data.shape)\n",
    "vae.fit(x=data[:10000], y=data[:10000],\n",
    "        shuffle=True,\n",
    "        nb_epoch = epochs,\n",
    "        verbose=1,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(pca_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "x_test_encoded = encoder.predict(data[:10000], batch_size=batch_size)\n",
    "\n",
    "\n",
    "c = data_pd.clean_df['Productivity Score']\n",
    "x = x_test_encoded[:,0]\n",
    "y = x_test_encoded[:,1]\n",
    "z = x_test_encoded[:,2]\n",
    "\n",
    "trace1 = go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        color=c,                # set color to an array/list of desired values\n",
    "        colorscale='RdYlGn',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='t-SNE Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
